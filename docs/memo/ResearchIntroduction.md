以下は **ゼミ発表資料の「導入〜背景〜従来研究〜新規性」までをそのままスライド化できるレベルの内容**をまとめたものです。
あなたの研究コンテキスト（継続学習 × Model merging × LoRA × Nested Learning）を、論理的に一枚のストーリーとして流れるように再構成しています。

必要なら、これをそのままスライド用に bullet 化したバージョンも作れます。

---

# 🔵 研究導入・背景まとめ（ゼミ資料用）

## 1. なぜ「継続学習（Continual Learning）」か？

現実世界のアプリケーションでは、モデルは一度学習して終わりではなく、**新しいタスク・新しいデータが連続的に登場する**。

* 例：

  * 画像分類器が新しいクラスを覚える
  * VLM が新しい概念を理解する
  * LLM がユーザ依存の知識を獲得する

しかし、一般的なニューラルネットは **古いタスクを忘れてしまう**（破滅的忘却）。

### 従来対策

* **正則化系**：EWC、SI、MAS など
* **リプレイ系**：過去データや生成データを保持
* **構造拡張系**：新しいタスクが来るたびに層やアダプタを増やす

近年では、**Adapter / LoRA を使った軽量な構造拡張による継続学習**が注目。

---

## 2. なぜ「Adapter / LoRA」が CL で注目されている？

### (1) パラメータ効率が良い

ベースモデルを凍結したまま、少量の追加パラメータで適応可能。

### (2) タスクごとに LoRA を持つことで忘却を軽減できる

（既存研究：CL-LoRA、LoRA-CL-Constraint、Adapter Fusion 系など）

### (3) モジュール化と合成がやりやすい

* Mixture-of-Adapters（MoA）
* Mixture-of-LoRA
* AdapterFusion
  など、「複数アダプタをどう組み合わせるか？」の研究が増加中。

---

## 3. しかし、現行の Mixture-of-Adapters / LoRA には“決定的な制約”がある

あなたが調査したように、MoA 系のポイントは：

> **入力またはタスクごとに “どのアダプタを使うか” をルータで決める。**

### △ つまり、**空間的（インプット依存）な“専門家分担”が主眼**

* 入力特徴から「どの専門家が担当するか」を選択
* タスクごとに増える LoRA を切り替える仕組み

### ❌ 一方で、「時間方向（タスク順）」を意識した設計にはなっていない

* 全アダプタが「同じ最適化スピード／同じ lr」で学習される
* 新タスクが来ると、過去タスクの Adapter/LoRA の相対的な重要度が崩れたりする
* 「短期的に出てくるタスク」「長期的に重要なタスク」を区別するメカニズムがない

**→ どれだけアダプタを増やしても、「時系列での知識の安定性・保存」はうまく扱えていない。**

---

## 4. Nested Learning の出現（Google 2024–2025）

Google の Nested Learning (NL) は、こういう構造的問題への新しいアプローチ。

### Nested Learning の主張（要点）

> **モデル内部に “更新速度の異なる複数のパラメータ層” を持たせることで、
> 長期記憶（ゆっくり更新）と短期記憶（高速更新）を使い分ける。**

### 対象は HOPE/Titans のような超巨大モデル

* fast/slow の階層をモデルアーキに内蔵
* 事前学習段階から多段階のメモリ更新を共訓練
* 巨大なアーキテクチャ改変が必要（普通の人には扱えない）

### ● しかし思想は非常に面白い

* 人間の記憶のような **時間スケールの分離**
* 自然な forgetting / consolidation
* 忘れたいものは fast に留まり、重要なものは slow に定着

---

## 5. ここで発想：「これ、Adapter/LoRAで模倣できない？」

Nested Learning のアイデアを丸ごと巨大モデルで再構成するのは非現実的。

しかし、

> **LoRA/Adapter は“モデルに追加でぶら下がる低ランク記憶”そのもの。
> なら LoRA に「fast」と「slow」の2種類を持たせれば、
> Nested Learning 的な時間スケール分離を再現できるのでは？**

という発想があなたの研究アイデア。

### この方向の意義

* 巨大事前学習モデルを再構築する必要なし
* ViT・CLIP など既存 PTM に簡単に追加できる
* 学習率や更新頻度を変えるだけで「fast/slowメモリ層」を構成可能
* CL において自然な“短期適応・長期保持”の両立を狙える

これは **Nested Learning × PEFT（LoRA）という新しい接合点**。

---

## 6. 既存研究との関係性（あなたの方向性が「空き」になっている理由）

### 6.1 Mixture-of-Adapters 系（MoA）

* 「複数アダプタを**空間的に選択**する」
* Router がその選択を担う
* タスクに応じてアダプタを追加する

🔻 **問題：時間スケールの概念がない**

* すべて同じ lr
* すべて同じ更新ループ
* “短命タスク”と“長期的に大事なタスク”が混ざってしまう

---

### 6.2 LoRA-based Continual Learning 系

例：CL-LoRA、LoRA-CL-Constrained、Dual-LoRA…

* LoRA の orthogonality 制約
* ClipGrad
* Rehearsal-free LoRA
  などの工夫はあるが…

🔻 **やはり「fast/slow の2タイムスケール」という視点はない**

* 1種類の LoRA がすべてのタスクに対応
* forgetting はロスや制約で防ぐが、構造的な分離はない

---

### 6.3 Nested Learning そのもの（HOPE）

* 完全に“事前学習段階の巨大アーキ設計”
* PTMを丸ごとNL化する
* 一般研究者は扱いにくい／CLの評価文脈とは違う

🔻 **LoRA × NL という接合は現時点で前例がほぼない**

* LoRA/Adapter を「fastメモリ・slowメモリ」として階層化する発想は新しい
* 既存の MoA とも NL とも違うニッチがある

---

## 7. 本研究の新規性（ゼミスライド用にまとめ）

ここが一番重要。
あなたの研究の “新規点” を 4 行で明確に。

### ★ 本研究の新規性（候補まとめ）

1. **LoRA に “fast” と “slow” の 2 タイムスケールを導入した初のアプローチ。**

   * lr, 更新頻度、consolidation による時間軸での分離。

2. **MoA（空間的専門家分割）ではなく、時間方向の役割分担に基づく新しい CL アーキテクチャ。**

3. **Nested Learning のアイデアを、既存PTMに後付け可能な軽量PEFTとして実装可能にした。**

4. **CLの安定性−可塑性トレードオフ（Plasticity–Stability Tradeoff）を
   “時間スケール”という新しい軸で改善する。**

オプション（v1）として：

5. **fast→slow の重み統合（consolidation）が
   “重要情報だけが残る”人間的忘却モデルを再現できる可能性。**

---

## 8. 研究目的を一文で（スライドにそのまま）

> **目的：**
> 継続学習において、従来の Adapter/LoRA が扱えなかった
> “時間方向の記憶分離（短期／長期）” を、Nested Learning の発想から
> **fast/slow LoRA による多段階メモリ構造として実現し、
> その有効性（忘却抑制・タスク順序への頑健性）を検証する。**

---

## 9. 調査に基づく位置取り（あなたの文脈に即して）

### あなたの研究の位置づけ

* Continual Learning（CL）：古い問題
* Adapter/LoRA：新しい実用路線
* MoA：モジュールを増やす流れ
* Nested Learning：巨大モデルの新パラダイム

➡ **その隙間にある “時間スケール×LoRA” の領域が完全に手付かず。**

これが今回の絶好のポジション。

---

# 🔵 スライド化イメージ（短い版）

スライドにするとこういう流れになります：

---

### ❶ 継続学習の課題

* 新タスクが到来すると、過去タスクを忘れる（破滅的忘却）
* Rehearsal, Regularization, Structural expansion 等が研究されてきた

---

### ❷ 最近の主流：Adapter / LoRA による軽量 CL

* パラメータ効率が良い
* 過去タスクの重みを保存しやすい
* MoA / Mixture-of-LoRA が盛ん

---

### ❸ しかし：MoA の限界

* 専門家選択（router）は **空間方向（input-dependent）** のみ
* 時間方向（task sequence）を扱う記憶構造を持たない
* 全アダプタが同じ lr / 更新速度 → “短期 vs 長期” の区別がつかない

---

### ❹ Nested Learning のアイデア

* パラメータを“fast”“slow”複数のスケールで更新
* 人間の短期記憶／長期記憶のような階層構造
* ただし巨大モデル前提（HOPE）、PTMを作り直す必要あり

---

### ❺ 本研究の提案：Nested LoRA

* 既存の ViT/CLIP などの PTM に後付け可能
* LoRA を「fast（高 lr / 高頻度更新）」＋「slow（低 lr / 低頻度）」の 2 層に分離
* 推論時は常に fast+slow の和
* （拡張）タスク間で fast→slow の重み統合（consolidation）

---

### ❻ 新規性

1. LoRA に時間スケール（fast/slow）を持たせた初の CL 設計
2. MoA とは異なる “時間方向” の専門家分離
3. Nested Learning を PEFT（LoRA）へと持ち込む新パラダイム
4. 安定性–可塑性の改善・タスク順序ロバストネスの向上を期待

---

必要なら、この流れをそのまま **PowerPoint スライドテンプレ化** した Markdown、
もしくは **図を含めた構造図** も作ります。

次に作りたいのは：

* Nested LoRA の図（fast/slow 2段メモリの視覚化）
* 既存MoAとの比較表
* 問題設定スライド（CILの流れ）
* 初期実験の設定スライド

などでしょうか？

---
---
* **今ある SEMA コードを「LoRAを1本だけ使うCILベースライン」に剥ぎ取る**
* そこから **その1本LoRAを「fast+slow付き Nested v2 LoRA」に拡張する**
って方針が一番安全そうです。

## SEMAコードを「LoRA1本のCIL」まで削る

これはかなりアリで、しかも **あなたがすでにコードを触っている**というアドバンテージがあります。

やるべきことはざっくり３ステップ：

### A-1. 「アダプタを増やす」部分を殺して、常に1個だけ使う

SEMA側でやっているのはだいたい：

* アダプタ（LoRA）を複数本管理するリスト or dict
* 新タスク or 拡張トリガーで `add_adapter(...)` みたいな処理
* forward時に「どのアダプタを通すか」を決めるルーティング（gating）

これらを全部つぶして、

* **最初に1つだけ LoRA（adapter）を生成**
* 以後、**常にそれだけ使う**
* forward も `adapter(x)` ではなく、
  既存の「単一LoRAを合成するパス」だけ残す

にします。

つまり SEMA を、

> 「LoRAをたくさん管理できるフレームワーク」
> → 「LoRAを1個だけ持ってる普通のCLコード」

にダウングレードするイメージ。

### A-2. CLプロトコル部分はそのまま活かす

* タスクループ
* リハーサル有無
* 評価プロトコル（joint testなど）

ここは **SEMAがすでに「CILとして正しく動くように」作り込んであるはず**なので、そのまま使うのが得。

あなたがすでに実験回せているのであれば、
「学習・評価の流れ自体は正しい」と見なしてよさそうです。

### A-3. その単一LoRAを「fast+slow付き Nested v2」に拡張する

LoRA 1本版ができたら、次にやるのは：

* LoRAの中身を

  ```text
  ΔW = ΔW_fast + ΔW_slow
  ```

  という形にする（2個のLoRAを足す）

* optimizer で

  * fast のパラメータグループ：高学習率
  * slow のパラメータグループ：低学習率 or 同じ + update interval を変える

* タスク終了時に

  * `slow += α * fast`
  * `fast = 0`

という処理を追加するだけです。

**重要ポイント：**

* ここでは **アダプタを増やすロジックは一切使わない**
  （「Nested LoRA v2 = 1本だけ、全タスク共有」）
* なので、SEMAの「混ぜ物」をほぼ切り離せる

---