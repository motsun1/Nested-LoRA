# 60 Questions & Answers公開版23

[**60QAの進め方	1**](#60qaの進め方)

[**１．はじめに・序論 / Introduction（0/10完了）	2**](#１．はじめに・序論-/-introduction（0/10完了）)

[**２．関連研究 / Related Work（0/5完了）	3**](#２．関連研究-/-related-work（0/5完了）)

[**３．問題設定 / Problem Statement（0/8完了）	3**](#３．問題設定-/-problem-statement（0/8完了）)

[**４．手法 / Method（0/11完了）	4**](#４．手法-/-method（0/11完了）)

[**５．実験設定 / Experimental Setup（0/11完了）	5**](#５．実験設定-/-experimental-setup（0/11完了）)

[**６．実験結果 / Experimental Results（0/14完了）	6**](#６．実験結果-/-experimental-results（0/14完了）)

[**７．結論 / Conclusions（0/3完了）	7**](#７．結論-/-conclusions（0/3完了）)

# １．はじめに・序論 / Introduction（0/10完了） {#１．はじめに・序論-/-introduction（0/10完了）}

1. **▲本研究の社会的背景は何か？ / What is the social background?**  
   現代の機械学習モデルは、現実世界のように 絶えず新しい概念・クラス・タスクが出現する環境で活用されることが増えている。画像分類モデル、VLM、LLM いずれも運用フェーズでは継続的なアップデートが必要であり、モデルが新規データを学び続ける能力は、社会的にますます重要となっている。 
2. **▲本研究のtarget task/problemは何か？ / What is the target problem of this work?**  
   本研究が扱う問題は、画像分類における クラスインクリメンタル学習（CIL） である。
   モデルがタスク系列に沿って新しいクラスを学習しつつ、古いタスクのデータに再アクセスできない環境で忘却を防ぐ必要がある。
3. **▲本研究のtarget problemの具体例（ユースケース）は何か？ / Explain a typical use case.**  
   * 現場の監視カメラが新しい物体クラスを観測するようになったとき
   * 工場ラインで新型製品が追加されるとき
   * ロボットが新しい環境へ適応する際
   これらはすべて「新しい概念を学びながら古い知識を保持する」ことが求められる典型的な CIL のユースケースである。  
4. **▲そのtarget problemが難しいと言う根拠は何か？既存手法が誤る例はどんなケースか？ / Why is this task challenging?**  
   最大の困難は 破滅的忘却（Catastrophic Forgetting） である。
   新タスクの勾配により、過去のタスクで最適化されていたパラメータが容易に上書きされてしまう。
5. **▲既存手法はなぜ不十分なのか？ / Why are conventional studies insufficient?**  
   Adapter/LoRA を用いた近年の継続学習はパラメータ効率が高く有効であるが、以下の限界がある：
   1. すべてのアダプタが同じ時間スケールで更新されるため、短期的・長期的な知識の区別ができない。
   2. Mixture-of-Adapters は“空間方向の専門家選択”に偏り、時間方向の記憶構造を持たない。
   3. LoRA-CL 系手法は勾配制約を課すものの、記憶を階層化する設計ではない。
6. **▲本研究では何を提案し、何を解決するのか？ / What is proposed and solved in this study?**  
   本研究では、Nested Learning の fast/slow 二段階記憶構造を参考に、
   LoRA を fast（短期記憶）/ slow（長期記憶）に分離した Nested LoRA を提案する。
7. **▲提案手法は既存手法と何が違うのか？主要な違いに絞って述べよ。 / What is the difference between the proposed and conventional methods?**  
   提案手法は、LoRA アダプタに **“時間スケール”という新軸** を導入した点で従来と異なる。
   fast/slow の学習率・更新頻度を分離することで、CL における「新タスク適応 vs 過去タスク保持」のトレードオフを構造的に制御できる。
8. **▲既存手法との違う部分は、なぜ導入するべきなのか？なぜ導入するとうまくいくと予想されるのか？ / Explain why the difference should be introduced.**  
   Nested Learning の知見より、**短期的に頻出する情報は fast に、長期的に残すべき情報は slow に蓄積される**と期待される。
   この二段階構造は、過学習や急激な忘却を防ぎつつ、新タスクへの迅速な適応を両立する。
9. **▲提案手法の新規性は何か？箇条書きせよ。 / What is the novelty of the proposed method?**  
   1. LoRA に fast/slow の二段階メモリ構造を持ち込んだ初の CL 手法
   2. 更新頻度と lr の差による“時間スケール分離”を実現
   3. Nested Learning を巨大事前学習モデルなしで実現する軽量アーキテクチャ
   4. SEMA など既存 MoA 系に容易に組み込める汎用性
10. **▲提案手法全体の構成をeye-catch figureを用いて示せ（通常6回修正ののち確定）。 / Show the eye-catch figure.**  
    「Backbone → SEMA Adapter → **Nested LoRA（Fast/Slow）** → 出力」
    Fast：毎ステップ更新、高 LR
    Slow：5-step更新、低 LR
    両者の和が Adapter 出力となる構造

# ２．関連研究 / Related Work（0/5完了） {#２．関連研究-/-related-work（0/5完了）}

1. **▲XXX分野のサーベイ論文を複数挙げよ。 / Explain about multiple survey papers in the related area.**  
   * Continual Learning Survey（Delange et al., 2021）
   * Parameter-Efficient Fine-Tuning Survey（Hu et al., 2022; Ding et al., 2023）
   * Vision Transformer in CL survey（Hayes & Kanan 2022）
   * Adapter/LoRA systematization（He et al., 2023）
   これらの調査から、本研究は CL × Adapter/LoRA × Model Merging の交差点に位置している。 （実際に存在するのか要チェック）
2. **▲論文を複数挙げて、１個目の関連分野を説明せよ。 / Explain the first related subfield and several related papers.**  
   主な研究：
   * Regularization 系：EWC, SI, MAS
   * Replay 系：iCaRL, DER
   * Structural 系：PackNet, HAT
   * Adapter 系：CL-LoRA, LoRA-CL-Constrained, MAM

   CLにおける主要な課題は破滅的忘却であり、各手法が異なる角度から安定性を確保しようとする。
3. **▲論文を複数挙げて、N個目の関連分野を説明せよ。（この項目を個数分コピーしてください） / Explain the N-th related subfield and several related papers.**  
   * AdapterFusion（Pfeiffer et al.）
   * LoRA（Hu et al., 2022）
   * MAM, LADA（MoA系）
   * LoRA-as-expert (Mixture-of-LoRA)

   しかし、**時間方向の階層構造（fast/slow）は扱われていない**。
4. **▲XXX分野の標準データセットについて説明せよ。 / Explain standard datasets in the related fields.**  
   Nested Learning では、巨大 Transformer のパラメータを fast/slow で分離し、
   学習ダイナミクスを階層的に制御する。
   しかし **PTM を作り直す必要があり、一般研究者が扱えるレベルではない。**
   本研究は、その **エッセンスを LoRA 層のみに転写した軽量版として位置づけられる。**
5. **▲提案手法と類似手法A（＋類似手法B、類似手法C）との違いは何か？ / What is the difference(s) between the proposed and related methods?**  
   | 手法              | 空間ルーティング | 時間スケール           | LoRA 分離 | 忘却抑制のメカニズム  |
   | --------------- | -------- | ---------------- | ------- | ----------- |
   | MoA/SEMA        | ○        | ×                | ×       | ルータによる専門家選択 |
   | CL-LoRA         | ×        | ×                | ×       | 勾配制約        |
   | **Nested LoRA** | ×        | **○（fast/slow）** | **○**   | 時間スケール分離    |
# ３．問題設定 / Problem Statement（0/8完了） {#３．問題設定-/-problem-statement（0/8完了）}

## **3-1 対象タスクの名称・内容（Target Problem）**
本研究の対象は **画像分類におけるクラスインクリメンタル学習（Class-Incremental Learning; CIL）** である。
CIL では、複数のタスクが時系列に与えられ、各タスクで新たなクラス集合が導入される。モデルは過去タスクのデータに再アクセスできない制約下で学習を進める必要があり、新タスクへの適応と過去タスク知識の保持を同時に満たさなければならない。
本研究では、事前学習済みの Vision Transformer (ViT) を凍結し、追加パラメータである LoRA/Adapter のみを更新する **パラメータ効率型継続学習（PEFT-CL）設定**を扱う。

## **3-2 望ましい出力・モデル挙動**
望ましいモデル挙動は次の 2 点である：
1. **可塑性（Plasticity）**：
   新しいクラスを含むタスクが導入された際、高精度に対応できること。
2. **安定性（Stability）**：
   過去タスクで獲得した分類能力を維持し、破滅的忘却（Catastrophic Forgetting）を生じさせないこと。
すなわち、タスク t 終了後のモデルは、それまでに観測した全てのクラス ( C_0 \cup C_1 \cup \dots \cup C_t ) に対して妥当な分類性能を維持していることが求められる。

## **3-3 代表例（図付き想定）**
典型例として CIFAR-100 を 10 クラスずつに分割した 10-task シナリオを考える。
モデルは Task 0 の 10 クラスを学習した後、Task 1〜9 で新しいクラスを段階的に学習するが、Task 0 のデータには二度とアクセスできない。
タスク 9 終了後にも Task 0 のクラスを正しく分類できていることが理想である。
（図では：時系列に沿ってクラスが増加 → 過去データが消える → 全100クラスでテスト）

## **3-4 与えられる入力**
入力は RGB 画像 ( x \in \mathbb{R}^{3 \times H \times W} ) であり、本研究では CIFAR-100 に従って ( H = W = 32 ) の低解像度画像を用いる。
各タスクでは、10 クラス分の画像群が与えられる。

## **3-5 求められる出力**
タスク t 終了後の出力は、これまでに出現したすべてのクラスに対するカテゴリラベルである。
タスク識別子（Task-ID）は与えられず、モデルは **単一の分類器**で全クラスの識別を行わなければならない。

## **3-6 用語定義（Updated）**
* **Task**：新しいクラス集合を含む学習単位。タスクごとにクラス集合は排他的。
* **Incremental Learning Step**：Task 0 → Task 1 → … の順序。
* **Base Model**：事前学習済みの ViT（本研究では凍結）。
* **LoRA / Adapter**：更新可能な追加パラメータ。
* **Fast LoRA**：新タスクに迅速に適応するための短期記憶パラメータ。
* **Slow LoRA**：複数タスクを通して保持される長期記憶パラメータ。
* **Fast→Slow Consolidation**：fast に蓄積された勾配方向を slow に統合し、長期記憶として固定化する操作。
* **MoE-style Fast Selection（Optional）**：複数の fast を並列に学習し、タスク固有の最適 expert を自動選択する仕組み。
* **Catastrophic Forgetting**：過去タスクの性能が新タスク学習によって急激に失われる現象。

## **3-7 本研究で扱わない前提（Assumptions / Exclusions）**
本研究では次を扱わない：
1. **Rehearsal / Replay Buffer**（過去データ保存）は使用しない。
2. **タスク識別子（Task-ID）を推論時に利用しない**（class-incremental の厳密設定）。
3. **Base Model の更新**は行わず、PEFTパラメータのみを更新する。
4. アンサンブル・蒸留・生成モデルによる補助データは使用しない。
5. Slow と fast の階層を 2 段階とし、それ以上の HOPE/Titans のような多段階構造は構築しない（実装を単純化するため）。

## **3-8 評価尺度（Metrics）**
標準的な **Top-1 精度（Accuracy）** を採用し、特に次の指標を重視する：
1. **Final Average Accuracy**：
   全タスク t の精度 ( \text{Acc}_t ) を平均した性能。
2. **Forgetting Behavior**：
   初期タスク（Task 0〜3 など）における性能維持率。
これらは CIL 研究において最も広く使用される評価指標であり、破滅的忘却の有無を直接計測できる。


# ４．手法 / Method（0/11完了） {#４．手法-/-method（0/11完了）}

## **4-1. 拡張対象と提案手法の位置づけ**
本研究は、Vision Transformer (ViT) を基盤とする継続学習手法 SEMA（Sparse Expandable Mixture-of-Adapters）を拡張し、
各 Adapter 内部に **Fast LoRA** と **Slow LoRA** の二段階メモリ構造を導入した **Nested LoRA** を提案する。
従来の LoRA-based CL は単一 LoRA を逐次上書きするため、新タスク適応と過去タスク保持を同時に満たすことが難しかった。
本研究では **Fast（短期記憶）→ Slow（長期記憶）の階層更新**を導入し、タスク間の時間スケール分離によって忘却抑制を実現する。

## **4-2. 一般性（他手法への適用可能性）**
本手法の拡張ポイントは LoRA を「fast/slow に二分する」という構造的変更のみであり、
AdapterFusion・MAM などの Adapter 系手法、CL-LoRA のような LoRA ベース CL、
あるいは LLM/VLM における PEFT にも適用可能である。
つまり、提案手法は **LoRA の一般化された時間階層化**であり、特定のアーキテクチャに依存しない。

## **4-3. 既存手法との主な違い（箇条書き）**
1. LoRA を **Fast（短期）/ Slow（長期）** の二系統に分離し、更新速度と更新頻度を独立に制御する点。
2. Slow LoRA をタスク境界でのみ更新し、学習中は安定状態を維持する点。
3. Fast LoRA をタスク専用の短期記憶として再初期化し、新タスクへの即応性を確保する点。
4. Consolidation（Fast→Slow）を Task Arithmetic または PAM-lite に基づき実行し、衝突の少ない統合を実現する点。
5. MoE 拡張では複数 Fast-LoRA を並列学習し、最も適応度の高い専門家を選択する構造も併用可能。

## **4-4. 提案手法の主要モジュール**
提案手法は次の 3 つの主要モジュールから構成される：
### **(1) Fast LoRA（短期記憶モジュール）**
高学習率で更新され、新タスクに迅速に適応するための短期メモリ。
### **(2) Slow LoRA（長期記憶モジュール）**
タスク境界時の統合により更新され、過去タスクの安定した情報を保持する長期メモリ。
### **(3) Consolidation Module（Fast→Slow 統合機構）**
Fast の更新方向を Slow に転写する仕組みであり、
・Task Arithmetic（素朴な加算）、
・PAM-lite（符号整合による干渉抑制）
のいずれかを選択可能。
MoE 拡張時には「Multiple Fast LoRA + Expert Selection Module」が追加される。

## **4-5. モデル構造（文章版）**
提案モデルでは、ViT の各 LoRA 適用層に対し **Fast LoRA と Slow LoRA の 2 つの低ランク更新**を持つ。
各層の最終出力は：
$
h = f_{\text{base}}(x) + \Delta_{\text{fast}}(x) + \Delta_{\text{slow}}(x)
$
* 学習中：Fast を更新し Slow は固定（最終出力は fast+slow を和算）
* タスク終了時：Fast→Slow 統合（alpha 付き、PAM-lite/Task Arithmetic）、fast はゼロ化して次タスクへ
* 推論時：Slow と Fast の和を出力するが、統合後は fast=0 なので実質 slow のみ（`nested_lora_eval_ablation` で slow_only/fast_only も可）
MoE 拡張では Fast が複数存在し、
$
\Delta_{\text{fast}}(x) = \Delta_{\text{fast}, k^*}(x)
$
となるように **最良 expert ( k^* )** をタスクごとに選択する。
並列 MoE では学習バッチを K 倍に複製し、チャンクごとに異なる fast を適用して同時学習する。

## **4-6. 入力の定義**
入力画像：
$
x \in \mathbb{R}^{3 \times 224 \times 224}
$
事前学習済み ViT-B/16 によりパッチ分割・埋め込みを行い、Transformer Encoder を通した後に Adapter + Nested LoRA（Fast/Slow）が適用される。

## **4-7. 特徴抽出（Backbone）**
特徴抽出には事前学習済みの ViT-B/16 を使用し、すべてのパラメータは完全に凍結する。
これにより、継続学習による破滅的忘却の影響は LoRA 層に限定され、PEFT としての計算効率と安定性が確保される。

## **4-8. 第 1 モジュール：Fast LoRA**
**Motivation**
新タスクへの迅速な適応を実現する短期メモリを導入するため。
**Role**
高学習率でタスク固有の変化を捉える。
**入出力**
入力特徴 ( h_{\text{in}} ) を低ランク写像によって調整し、
$
\Delta_{\text{fast}} = B_f A_f h_{\text{in}}
$
**構造**
ランク r の LoRA 行列 ( A_f, B_f ) を用いる。タスク開始時ごとに再初期化する。

## **4-9. 第 2 モジュール：Slow LoRA**
**Motivation**
過去タスクの情報を安定して保持する長期メモリを導入するため。
**Role**
低学習率またはタスク境界での更新によって、安定した知識保持を実現する。
**入出力**
$
\Delta_{\text{slow}} = B_s A_s h_{\text{in}}
$
**構造**
Fast と同じランク構造だが、更新頻度は大幅に低い。推論では Slow のみ使用する。

## **4-10. 予測の定義**
最終的な分類器 ( W ) に CLS トークン出力 h を入力して
$
\hat{y} = \mathrm{softmax}(W h)
$
を得る。
ここで、
$
h = f_{\text{base}}(x) + \Delta_{\text{fast}}(x) + \Delta_{\text{slow}}(x)
$

## **4-11. 損失関数**
タスク t の学習では標準的なクロスエントロピー損失
$
\mathcal{L}*{\text{CE}} = -\sum*{c} y_c \log \hat{y}_c
$
を用いる。
追加の distillation や replay は使用せず、**純粋な rehearsal-free CL** で性能を評価する。


## **4-12. Fast→Slow 統合ルール（Task Arithmetic / PAM-lite）**
* **Task Arithmetic (TA)**：各タスク終了時に `slow += α * fast`（α=0.1）で単純加算し、fast をゼロ化。
* **PAM-lite**：`p_s * p_f >= 0` の要素のみ加算し、符号が逆の成分は抑制して干渉を減らす。fast をゼロ化。`nested_lora_consolidation_method="pam"` で有効化し、ログに許容/抑制要素数を出力。
* **タイミング**：consolidation interval=1（毎タスク）で実行。

## **4-13. MoE 的拡張（Parallel Competition + Validation Selection）**
* **複数 fast の lr 多様化**：Fast を K=4 用意し、`lr_fast=0.01 × [1.0, 0.5, 0.1, 0.03]` で並列学習。
* **並列学習**：学習バッチを K 倍に複製し、チャンクごとに異なる fast にルーティングして同一データを同時学習（Parallel MoE）。
* **検証ベース選択**：各タスクの train から 10%（`moe_val_ratio=0.1`、クラス均等）を val にホールドアウト。タスク終了時に val 精度トップの fast を選び、TA または PAM-lite で slow に統合し fast をリセット。選択履歴を記録。
* **推論**：統合後は fast がゼロ化されるため実質 slow のみを使用（CIL 条件を満たす）。`nested_lora_eval_ablation` で slow_only/fast_only の切替も可能。


# ５．実験設定 / Experimental Setup（0/11完了） {#５．実験設定-/-experimental-setup（0/11完了）}

## **5-1. データセット（Dataset）**
本研究では、継続学習の標準ベンチマークである **CIFAR-100** を使用する。
CIFAR-100 は 100 クラス・50,000 訓練画像・10,000 テスト画像から構成され、
1 画像は RGB の ( 32 \times 32 ) 解像度である。

## **5-2. アノテーション**
CIFAR-100 は既に人手でクラスラベルが付与された標準データセットであり、
本研究では追加アノテーションは行っていない。

## **5-3. 標準データセットを使用した理由**
CIFAR-100 は以下の理由で CIL 研究に広く採用されているため標準データセットを使用した：
1. クラス数（100）が十分大きく、忘却の挙動を観察しやすい。
2. 10 クラス × 10 タスクの **Task-split 設定**が確立しており、
   多くの CL 手法（EWC, SI, DER, CL-LoRA など）と公平に比較できる。
3. 画像解像度が低く実験コストが小さいため、
   **Chain / MoE / consolidation method のアブレーションを多数実行できる。**

## **5-4. データ前処理・データ拡張**
* クラスをランダムにシャッフルし、**10 クラス × 10 タスク**に等分割（Class-Incremental）。
* 画像は 224 解像度で学習するため、変換は `iCIFAR224` 設定を使用：
  * Train: `RandomResizedCrop(224, scale=(0.05,1.0))` + `RandomHorizontalFlip` + `ToTensor`
  * Test: `Resize`→`CenterCrop(224)` + `ToTensor`
  * 正規化は行っていない（現行実験ログ準拠）。

## **5-5. データセット統計情報**
* **Train**：50,000
* **Test**：10,000
* **Class 数**：100
* **Task 数**：10
* **1 クラスあたりサンプル数**：500（train）・100（test）
* **画像サイズ**：( 3 \times 32 \times 32 )

## **5-6. Train / Validation / Test の分割**
* **Train**：CIFAR-100 公式 train（224 変換）
* **Validation**：MoE 実験のみ各タスク train の 10%（クラス均等）をホールドアウト（`moe_val_ratio=0.1`）
* **Test**：CIFAR-100 公式 test（224 変換）
  → 各タスク終了時に **全 100 クラス**で評価。

## **5-7. 各セットの利用方法**
* **Training Set**：タスク t の Fast / MoE Fast を学習。
* **Validation Set**：MoE のみで使用し、各タスク終了時に **best expert を選択**（early stopping は未使用）。
* **Test Set**：Task 0〜9 の各タスク終了後に全クラス分類精度を測定。

## **5-8. 実験のハイパーパラメータ（最新プロトコル対応）**
| Hyperparameter         | Chain (Step1)                     | MoE (Step2, parallel)                                   |
| ---------------------- | --------------------------------- | ------------------------------------------------------- |
| Backbone               | ViT-B/16（凍結）                  | 同左                                                    |
| Adapter                | SEMA Adapter + Nested LoRA        | SEMA Adapter + **Slow + 4 Fast experts**                |
| LoRA Rank              | 16 (Fast/Slow 共通)               | 16 (Fast/Slow 共通)                                     |
| Optimizer              | SGD                               | SGD                                                     |
| Base LR                | 0.005                             | 0.005                                                   |
| lr_fast                | 0.01                              | 0.01 × multipliers `[1.0, 0.5, 0.1, 0.03]`              |
| lr_slow                | 0.001                             | 0.001                                                   |
| Batch Size             | 32                                | 32（バッチを K=4 に拡張し並列学習）                     |
| Epochs per Task        | 5 (`func_epoch`)                  | 5                                                       |
| Consolidation Method   | Task Arithmetic / PAM-lite        | Task Arithmetic / PAM-lite（best expert を slow に統合）|
| Consolidation Alpha    | 0.1                               | 0.1                                                     |
| Consolidation Timing   | 各タスク終了時                    | 各タスク終了時                                          |
| Validation Split       | なし                              | `moe_val_ratio=0.1` で expert selection                 |

**ポイント**：
* PAM-lite は `nested_lora_consolidation_method="pam"` が正しく伝搬するよう修正済み（2025-12-05 デバッグノート）。
* MoE は並列競合型：拡張バッチを 4 分割し、専門家ごとに異なる lr で同一データを学習 → 検証精度トップを slow にマージ。

## **5-9. パラメータ数と計算量**
* **Base model（ViT-B/16）**：凍結のためパラメータ不変
* **Nested LoRA（Fast + Slow）**：
  * 1 Adapter 層あたり 約 76.9k パラメータ
  * MoE（4 fast）では fast が 4 倍になるが slow は 1 つのみ
* **計算量**：
  LoRA による低ランク写像の追加計算のみで、
  ViT 本体に比べて FLOPs 増加はごく小さい。
※ 実験として重要なのは「SEMA の bottleneck32 と Nested LoRA rank16×2 がパラメータ等価（param-matched）」である点。

## **5-10. ハードウェア**
ローカル GPU 環境（48GB 級, CUDA 12, PyTorch 2.x）で実行。詳細な型番/CPU/RAM は要確認。

## **5-11. 学習時間・推論時間**
* **学習時間**：今回の 224 設定・5epoch/タスクの再実験は計測中（値は未確定）。
* **推論時間**：Fast は推論時に用いず Slow のみ適用。ViT-B/16 と同等オーダー。

# ６．実験結果 / Experimental Results（0/14完了） {#６．実験結果-/-experimental-results（0/14完了）}

1. **▲ベースライン手法との定量的比較結果を示せ。 / Show the quantitative comparison results with the baseline method(s).**  
   CIFAR-100 10-task シナリオにおける各手法の実験結果を以下に示す。

   **主要結果（2025-12-06 実験）**：
   | 手法                      | Final Accuracy (%) | Average Accuracy (%) |
   | ------------------------- | ------------------ | -------------------- |
   | Step1: Nested LoRA + TA   | 81.34              | 87.31                |
   | Step1: Nested LoRA + PAM  | 81.27              | 87.29                |
   | **Step2: MoE + TA**       | **81.69**          | **87.57**            |
   | **Step2: MoE + PAM**      | **81.71**          | **87.50**            |

   **Top-1 精度の推移（タスクごと）**：
   | 手法           | T0   | T1    | T2    | T3    | T4    | T5    | T6    | T7    | T8    | T9    |
   | -------------- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
   | Step1 TA       | 96.5 | 92.75 | 90.97 | 89.55 | 87.14 | 85.25 | 85.16 | 82.66 | 81.80 | 81.34 |
   | Step1 PAM      | 96.4 | 92.80 | 90.93 | 89.55 | 87.20 | 85.17 | 85.19 | 82.64 | 81.73 | 81.27 |
   | Step2 MoE+TA   | 96.5 | 92.65 | 91.10 | 89.28 | 87.44 | 85.60 | 85.71 | 83.29 | 82.47 | 81.69 |
   | Step2 MoE+PAM  | 96.5 | 92.55 | 91.00 | 89.22 | 87.38 | 85.52 | 85.70 | 83.14 | 82.30 | 81.71 |

   **クラスグループ別精度（Task 9 終了後）**：
   | 手法           | 00-09 | 10-19 | 20-29 | 30-39 | 40-49 | 50-59 | 60-69 | 70-79 | 80-89 | 90-99 |
   | -------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
   | Step1 TA       | 78.7  | 77.3  | 89.1  | 83.1  | 83.7  | 74.3  | 85.4  | 74.7  | 85.2  | 81.9  |
   | Step1 PAM      | 78.9  | 77.3  | 89.0  | 82.8  | 83.5  | 74.4  | 85.5  | 74.5  | 85.1  | 81.7  |
   | Step2 MoE+TA   | 79.7  | 79.9  | 89.6  | 83.6  | 78.7  | 78.3  | 85.5  | 76.3  | 84.3  | 81.0  |
   | Step2 MoE+PAM  | 79.8  | 80.2  | 89.6  | 83.9  | 78.9  | 77.9  | 85.5  | 76.1  | 84.3  | 80.9  |

2. **▲何をベースライン手法（群）としたか？ / What was used as the baseline method(s)?**  
   * **Step1（Chain 方式）**：Nested LoRA の基本構成。Fast→Slow の統合を Task Arithmetic (TA) または PAM-lite で実行。
   * **Step2（MoE 方式）**：Step1 を拡張し、複数の Fast LoRA expert を並列学習し、検証精度に基づき best expert を選択して Slow に統合。

3. **▲上記ベースラインを選んだ理由を説明せよ。 / Explain the reason for choosing the above baseline(s).**  
   * **Step1 vs Step2 の比較**：MoE による expert selection の効果を検証するため。
   * **TA vs PAM の比較**：統合手法（Task Arithmetic vs PAM-lite）の違いによる性能差を検証するため。
   本実験では、提案手法の各コンポーネント（fast/slow 分離、MoE 拡張、統合手法）の貢献を段階的に評価できる設計とした。

4. **▲評価尺度（群）について数式で説明せよ。複数あるのであれば、どれが主要尺度か？ / Explain the metric(s) by using equations. Which one is the primary metric?**  
   評価指標は 学習後の全クラス分類精度（Top-1 Accuracy）：
   $
   \text{Acc}_t = \frac{\#\text{correct predictions}}{\#\text{all test samples}}
   $
   主要指標は 2 つ：
   1. **Final Accuracy**：最終タスク（Task 9）終了後の全 100 クラスに対する精度
   2. **Average Accuracy**：各タスク終了時の精度を平均した値
   $
   \text{Avg Acc} = \frac{1}{T} \sum_{t=0}^{T-1} \text{Acc}_t
   $

5. **▲なぜそれらの評価尺度を使用したのか？他の評価尺度ではダメなのか？ / Why did you use those evaluation metrics? Why not other metrics?**  
   クラスインクリメンタル学習では、
      * **Final Accuracy**：最終的な統合性能（全タスク学習後の性能）
      * **Average Accuracy**：学習過程での忘却の度合い（タスク途中の性能維持）

   を総合的に評価するため、両指標が標準的に使用される。
   F1 や AUC はマルチクラス分類では利点が乏しいため使用しない。

6. **▲ベースラインと提案手法の性能を（相対的な性能差ではなく）絶対的な値で示せ。 / Show the performance of the baseline and proposed methods in absolute values, not relative performance differences.**  

   **Step1 TA vs Step2 MoE+TA の比較**：
   | Task          | Step1 TA | Step2 MoE+TA | Difference |
   | ------------- | -------- | ------------ | ---------- |
   | T0            | 96.50    | 96.50        | ±0.00      |
   | T1            | 92.75    | 92.65        | -0.10      |
   | T2            | 90.97    | 91.10        | +0.13      |
   | T3            | 89.55    | 89.28        | -0.27      |
   | T4            | 87.14    | 87.44        | +0.30      |
   | T5            | 85.25    | 85.60        | +0.35      |
   | T6            | 85.16    | 85.71        | +0.55      |
   | T7            | 82.66    | 83.29        | +0.63      |
   | T8            | 81.80    | 82.47        | +0.67      |
   | T9            | 81.34    | 81.69        | +0.35      |
   | **Avg Acc**   | 87.31    | 87.57        | **+0.26**  |

   **特徴的な点**：
   * MoE 拡張により Average Accuracy が **+0.26%** 向上
   * 特に後半タスク（T5〜T8）で **+0.35〜0.67%** の改善が見られる
   * 旧タスク（00-09, 10-19）の精度も向上（+1.0, +2.6 ポイント）

   **Step1 PAM vs Step2 MoE+PAM の比較**：
   | Task          | Step1 PAM | Step2 MoE+PAM | Difference |
   | ------------- | --------- | ------------- | ---------- |
   | T0            | 96.40     | 96.50         | +0.10      |
   | T1            | 92.80     | 92.55         | -0.25      |
   | T2            | 90.93     | 91.00         | +0.07      |
   | T3            | 89.55     | 89.22         | -0.33      |
   | T4            | 87.20     | 87.38         | +0.18      |
   | T5            | 85.17     | 85.52         | +0.35      |
   | T6            | 85.19     | 85.70         | +0.51      |
   | T7            | 82.64     | 83.14         | +0.50      |
   | T8            | 81.73     | 82.30         | +0.57      |
   | T9            | 81.27     | 81.71         | +0.44      |
   | **Avg Acc**   | 87.29     | 87.50         | **+0.21**  |

7. **▲実験結果は統計的に有意（p\<0.05）であったか？ / Were the experimental results statistically significant (p\<0.05)?**  
   現時点では seed=1993 の 1 回のみの実験である。統計的有意性の検証には複数 seed での追加実験が必要。
   
   ただし、以下の傾向は一貫している：
   * MoE 拡張（Step2）は Step1 より一貫して高い Average Accuracy を達成
   * 後半タスク（T5〜T8）での改善が顕著
   * TA と PAM の差は小さい（0.07% 以内）

8. **▲定性的結果：提案手法が成功した例（N個）を示せ。Ground Truth、ベースライン手法、提案手法による予測結果をそれぞれ示せ。 / Qualitative results: Show examples (N) of successful cases of the proposed method. Show the Ground Truth, predictions by the baseline method, and predictions by the proposed method respectively.**  
   
   **成功例の特徴**：
   1. **旧タスクの知識保持**：クラスグループ 00-09 の精度が Step1 の 78.7% から Step2 MoE+TA で 79.7%（+1.0%）に向上。
   2. **中間タスクの改善**：クラスグループ 10-19 で 77.3% → 79.9%（+2.6%）と大幅に改善。MoE による expert selection が効果的に機能している。
   3. **後半タスクでの安定性**：T5〜T8 の精度推移が Step1 より緩やかに低下（忘却抑制効果）。

9. **▲定性的結果：提案手法が失敗した例（M個、N\>M）を示せ。なぜ失敗したのか？ / Qualitative results: Show M examples of failure cases of the proposed method (where N\>M). Why did they fail?**  
   
   **失敗例の特徴**：
   1. **クラスグループ 40-49 の精度低下**：Step1 TA (83.7%) → Step2 MoE+TA (78.7%) で **-5.0%** と大幅に低下。MoE の expert selection が当該タスクで不適切な expert を選んだ可能性。
   2. **新タスク（90-99）の微小な低下**：81.9% → 81.0% (-0.9%)。Slow への統合時に新タスク固有の情報が一部失われた可能性。

10. **▲Ablation studyにおいて何のために何を取り除いたかを説明せよ。 定量的結果に基づき、取り除いた要素が有効だったことを示せ。なぜ有効だったのかを説明せよ。 / Explain what is ablated.**  

    **Ablation 1: 統合手法の比較（TA vs PAM）**
    | 設定            | Final Acc | Avg Acc | 差分     |
    | --------------- | --------- | ------- | -------- |
    | Step1 TA        | 81.34     | 87.31   | baseline |
    | Step1 PAM       | 81.27     | 87.29   | -0.02    |
    | Step2 MoE+TA    | 81.69     | 87.57   | +0.26    |
    | Step2 MoE+PAM   | 81.71     | 87.50   | +0.19    |

    **結論**：
    * TA と PAM の差は微小（0.07% 以内）であり、統合手法の選択は大きな影響を与えない。
    * MoE 拡張の効果（+0.2〜0.3%）の方が統合手法の選択より支配的。

    **Ablation 2: MoE 拡張の効果**
    * Step1 → Step2 で一貫して Average Accuracy が向上（+0.21〜0.26%）
    * 特に後半タスクでの忘却抑制に効果あり
    * expert selection により、タスクごとに最適な学習率の Fast LoRA が選択されている

11. **▲混同行列（Confusion matrix）を示せ。 / Show the confusion matrix.**  
    （詳細な混同行列は別途可視化が必要）

12. **▲提案手法の失敗例は予測結果の中に合計何サンプルあったか？ / How many failure cases were included in the prediction results?**  
    * **Step2 MoE+TA**：全 10,000 テストサンプル中、誤分類は **1,831 サンプル**（Final Acc 81.69%）
    * **Step2 MoE+PAM**：全 10,000 テストサンプル中、誤分類は **1,829 サンプル**（Final Acc 81.71%）

13. **▲失敗例を人手でカテゴリに分類せよ。各カテゴリの定義を示せ。 / Classify the failure cases into categories manually. Show the definitions of each category.**  
    （詳細な失敗例分析は追加実験が必要）

14. **▲失敗の主要な要因（main bottleneck）とpossible solutionについて説明せよ。 / Explain about the main bottleneck and the possible solution.**  
    
    **Main bottleneck 1：特定クラスグループでの精度低下（40-49）**
    * MoE の expert selection が一部タスクで不適切な選択を行っている可能性
    * **Possible Solution**：expert selection の検証データ量を増やす（現在 10%）、または複数 expert のアンサンブルを検討

    **Main bottleneck 2：TA と PAM の差が小さい**
    * PAM-lite による符号整合フィルタリングの効果が限定的
    * **Possible Solution**：より強力な干渉抑制手法（e.g., gradient projection）の導入

    **Main bottleneck 3：新タスク精度の微小低下**
    * Slow への統合時に新タスク固有の情報が薄まる
    * **Possible Solution**：consolidation alpha の適応的調整、または新タスク専用の residual path の追加

# ７．結論 / Conclusions（0/3完了） {#７．結論-/-conclusions（0/3完了）}

1. **▲本研究ではどのようなタスクを扱ったか？ / What kind of task was addressed?**  
   本研究では、画像分類における クラスインクリメンタル学習（Class-Incremental Learning; CIL） を対象とした。特に、事前学習済み ViT を凍結し、追加アダプタ（LoRA）によって継続学習を実現する PEFTベースの継続学習に焦点を当てた。

2. **▲本研究の貢献（contributions）を過去形で箇条書きせよ。 / List the contributions of this study in the past tense.**  
   1. Nested Learning の fast/slow 二段階メモリ構造を LoRA に導入した **Nested LoRA** を提案した。
      * 巨大モデル HOPE/Titans のアイデアを、PEFT に適用可能な軽量形で再構成した。
   2. Nested LoRA を SEMA の Adapter framework に統合し、Frozen ViT に対して実装した。
   3. **MoE 拡張**（複数 Fast LoRA expert の並列学習 + 検証ベース選択）を導入し、タスクごとに最適な expert を自動選択する仕組みを構築した。
   4. CIFAR-100 10-task 実験において、以下の結果を得た：
      * **Step1（Chain 方式）**：Final Acc 81.34%、Avg Acc 87.31%（TA 使用時）
      * **Step2（MoE 方式）**：Final Acc **81.71%**、Avg Acc **87.57%**（MoE+TA 使用時）
      * MoE 拡張により Average Accuracy が **+0.26%** 向上し、特に後半タスク（T5〜T8）で顕著な改善を確認した。
   5. Task Arithmetic (TA) と PAM-lite の比較を行い、両手法の差は微小（0.07% 以内）であることを示した。
   6. MoE による expert selection が、旧タスクの知識保持（クラス 00-09: +1.0%、10-19: +2.6%）に有効であることを実証した。
  
3. **▲将来研究は何か？ / What is the future study?**  
   1. **複数 seed での統計的検証**
      * 現在は seed=1993 の 1 回のみの実験であり、複数 seed での再現性検証が必要。
   2. **Expert selection の改善**
      * 特定クラスグループ（40-49）での精度低下を防ぐため、selection 手法の改良や複数 expert のアンサンブルを検討。
   3. **より強力な統合手法の探索**
      * TA/PAM の差が小さいため、gradient projection など他の干渉抑制手法を検討。
   4. **他データセット・他モダリティへの拡張**
      * ImageNet-R、DomainNet など大規模データセットでの検証。
      * LoRA を多用する LLM/VLM への適用。
   5. **Task-order robustness の検証**
      * 短命タスク（rare / short-lived tasks）を挿入し、Nested LoRA の選択的記憶保持の働きを評価する。
