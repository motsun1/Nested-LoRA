# 今後の解析計画: Nested LoRA v2

初期実験とアブレーションスタディに基づき、重要な不一致点と興味深い挙動が確認されました。次フェーズの解析計画は以下の通りです。

## 1. 「Combined と Slow-Only の不一致」を調査する

**観察**: Combined 精度（46.11%） >> Slow-Only 精度（28.01%）。
**理論**: Combined = Slow + Fast。Fast を 0 にリセットすれば、Combined は Slow に等しくなるはず。
**仮説**:
1.  **Fast 重みがゼロではない**：統合（consolidation）メカニズムが重みをゼロにしていない、あるいは統合後に更新されている可能性がある。
2.  **チェックポイントの不一致**：メモリ内のモデル（Combined）が保存されたチェックポイント（Slow-Only のソース）と異なっている可能性がある。

**アクション項目**:
- **統合処理をデバッグ**：`zero_()` の直後および `eval_task` の前に `fast_norm` を出力するログを追加する。
- **チェックポイントを検証**：チェックポイントをロードして `fast_norm` を出力する。
- **オプティマイザを確認**：統合後にオプティマイザがステップしていないことを確認する。

## 2. 「Slow-Only の性能低下」を解析する

**観察**：Slow-Only（28.01%） < Fast-Only/Frozen（39.57%）。
**意味**：蓄積された「Slow」重みがバックボーンの表現を害している。
**仮説**：
1.  **破壊的な蓄積**：`slow += alpha * fast` が時間とともにノイズや競合する特徴を加えている可能性。
2.  **Alpha が大きすぎる**：`alpha=0.1` が攻撃的すぎる可能性。
3.  **ドリフト**：slow 重みが事前学習されたマニフォールドから逸脱している可能性。

**アクション項目**：
- **Alpha スイープ**：より小さい alpha（例：0.01、0.05）で劣化が減るかテストする。
- **直交性チェック**：`slow` と `fast` の更新間のコサイン類似度を測定する。
- **特徴可視化**：Frozen と Slow-Only の特徴空間（t-SNE / PCA）を可視化し、クラス分離の様子を見る。

## 3. 「Fast-Only の性能」を理解する

**観察**：Fast-Only（39.57%）は Frozen バックボーンの性能と等しい。
**文脈**：単一 LoRA ベースライン（45.92%）はこれを改善している。
**目標**：Nested LoRA が「Slow」知識を活用してこれを大きく上回ること。

**アクション項目**：
- **Fast-Only トレーニング**：Fast のみを学習し（各タスクでリセット）、Slow を一切更新しない実験を実施し、独立タスク学習のベースラインを確立する。

## 4. 手法の改善

単純な加算による Slow の蓄積が有害であることが判明した場合：
- **代替を検討**：
    - **EMA**：`slow = (1-beta)*slow + beta*fast`（加算の代わりに）。
    - **選択的マージ**：Fisher 情報量や SVD に基づいて「重要」な `fast` 成分のみをマージする。
    - **マスキング**：干渉を防ぐために `slow` 重みにマスクを適用する。

## 要約
最優先事項は「Combined が良いのに Slow-Only が悪い理由の解明」です。これにより現在動作している実際のメカニズム（おそらく意図せず Fast がゼロでないこと）が明らかになります。
